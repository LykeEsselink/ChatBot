{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a webpage\n",
    "def read_in_page(url):\n",
    "    #Query the website and return the html to the variable 'page'\n",
    "    page = urllib.urlopen(url)\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    return(soup)\n",
    "\n",
    "\n",
    "# Get all relevant links in a webpage\n",
    "def get_links(page):\n",
    "    links = page.find_all(\"a\", class_=\"icon-arrow\")\n",
    "    links_new = []\n",
    "    for link in links:\n",
    "        sep = '?'\n",
    "        rest = link['href'].split(sep, 1)[0]\n",
    "        links_new.append(rest)\n",
    "    return(links_new)\n",
    "\n",
    "\n",
    "# Returns a dictionary {study-name: az-url}\n",
    "def get_links_studies(page):\n",
    "    links = page.find_all(\"a\", class_=\"icon-arrow\")\n",
    "    links_new = {}\n",
    "    for link in links:\n",
    "        sep = '?'\n",
    "        rest = link['href'].split(sep, 1)[0]\n",
    "        # Get rid of everything before \"student\" and replace with https://\n",
    "        temp = rest.split('student')\n",
    "        rest = 'https://student' + temp[1]\n",
    "        if rest.endswith('/'):\n",
    "        # only do this if there isnt a slash at the end of rest\n",
    "            links_new[link.string] = rest + \"az\"\n",
    "        else:\n",
    "            links_new[link.string] = rest + \"/az\"\n",
    "    return(links_new)  \n",
    "\n",
    "\n",
    "def get_az_links(az_url):\n",
    "    az_page = read_in_page(az_url)\n",
    "    az_links = get_links(az_page)\n",
    "    az_links_new = []\n",
    "\n",
    "    # get all the links on an AZ page\n",
    "    for link in az_links:\n",
    "        link = \"http://www.student.uva.nl\" + link\n",
    "        az_links_new.append(link)\n",
    "    return(az_links_new)\n",
    "\n",
    "\n",
    "# Returns a list of keywords when given a question URL.\n",
    "def get_keywords(question_url):\n",
    "    # grab keywords with beautiful soup\n",
    "    question_page = read_in_page(question_url)\n",
    "    keyword_tag = question_page.findAll(\"meta\", {\"name\": 'keywords'})\n",
    "    if keyword_tag:\n",
    "        keywords = keyword_tag[0]['content']\n",
    "        keywords_list = keywords.split(\",\")\n",
    "        return(keywords_list)\n",
    "    else:\n",
    "        return([])\n",
    "\n",
    "# Takes URL returns text from that page\n",
    "def article_text(url):\n",
    "    page = urllib.urlopen(url)\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    info = \"\"\n",
    "    [x.extract() for x in soup.findAll('h1')] # get rid of headers\n",
    "    [x.extract() for x in soup.findAll('h2')] # get rid of headers\n",
    "    [x.extract() for x in soup.findAll('h3')]\n",
    "    [x.extract() for x in soup.findAll('p', class_=\"meta\")]\n",
    "    \n",
    "    for line in soup.find_all(\"article\", class_ = \"eight columns\"):\n",
    "        info = info + line.text\n",
    "    info = info.replace('\\n', ' ')\n",
    "    info = info.replace('\\r', ' ')\n",
    "    info = info.replace('\\t', ' ')\n",
    "    info = ' '.join(info.split())\n",
    "    #info = re.split(r'\\.(?!\\d)', info)\n",
    "    return info\n",
    "\n",
    "# Makes a json file for each article in a A-Z page \n",
    "def make_az_jsons_english(link, n, study_name):\n",
    "    question_page_dict = {}\n",
    "    keywords = get_keywords(link)\n",
    "    text = article_text(link)\n",
    "        \n",
    "    question_page_dict['level'] = study_name\n",
    "    question_page_dict['url'] = link\n",
    "    question_page_dict['keywords'] = keywords\n",
    "    question_page_dict['text'] = text\n",
    "        \n",
    "    # put question_page_dict into a JSON file\n",
    "    filename = str(n) + \"-study-fnwi.json\"\n",
    "        \n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(question_page_dict, outfile)\n",
    "                \n",
    "    #print(\"link done\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the UvA website and creating JSON files for each article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Watson had a limit on the amount of documents that could be uploaded, we had to be selective about choosing which pages we would train. We choose the general english A-Z page and some masters of FNWI, since these were in english and all the A-Z pages of bachelor studies were in dutch.\n",
    "\n",
    "In the cell below we take the url of the studypage and see which studies it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://student.uva.nl/ai/az': [\"Artificial Intelligence (Master's)\"],\n",
       " 'https://student.uva.nl/bcs/az': [\"Brain and Cognitive Sciences (Master's)\"],\n",
       " 'https://student.uva.nl/bmed/az': [\"Biomedical Sciences (Master's)\"],\n",
       " 'https://student.uva.nl/bs/az': [\"Biological Sciences (Master's)\"],\n",
       " 'https://student.uva.nl/chem/az': [\"Chemistry (Master's)\"],\n",
       " 'https://student.uva.nl/cls/az': [\"Computational Science (Master's)\"],\n",
       " 'https://student.uva.nl/es/az': [\"Earth Sciences (Master's)\"],\n",
       " 'https://student.uva.nl/fs/az': [\"Forensic Science (Master's)\"],\n",
       " 'https://student.uva.nl/is/az': [\"Information Studies (Master's)\"],\n",
       " 'https://student.uva.nl/log/az': [\"Logic (Master's)\"],\n",
       " 'https://student.uva.nl/ls/az': [\"Life Sciences (Master's)\"],\n",
       " 'https://student.uva.nl/math/az': [\"Mathematics (Master's)\"],\n",
       " 'https://student.uva.nl/mph/az': [\"Mathematical Physics (Master's)\"],\n",
       " 'https://student.uva.nl/phys-astro/az': [\"Astronomy and Astrophysics (Master's)\",\n",
       "  \"Physics (Master's)\",\n",
       "  \"Physics and Astronomy (Master's)\"],\n",
       " 'https://student.uva.nl/se/az': [\"Software Engineering (Master's)\"],\n",
       " 'https://student.uva.nl/sfm/az': [\"Stochastics and Financial Mathematics (Master's)\"],\n",
       " 'https://student.uva.nl/sne/az': [\"System and Network Engineering (Master's)\"]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_az_links = {}\n",
    "\n",
    "# read in page and for each study get the URL of the A-Z page\n",
    "page = read_in_page('http://student.uva.nl/opleidingen/opleidingenlijst.html?t=fnwi&t=master')\n",
    "studies_dict = get_links_studies(page)\n",
    "for study, az_link in studies_dict.items():\n",
    "    if az_link not in unique_az_links:\n",
    "        unique_az_links[az_link] = [study]\n",
    "    else: \n",
    "        unique_az_links[az_link].append(study)\n",
    "    \n",
    "unique_az_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were some troubles when running this automatically, it would create an amount of JSON files and then it would just stop making new ones, even though everything was still running. So a solutions was to do it seperately for each A-Z link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the articles of an A-Z page\n",
    "url = 'https://student.uva.nl/ai/az'\n",
    "az_links_per_study = get_az_links(url)\n",
    "\n",
    "i = 0\n",
    "# for each article make a json file\n",
    "for link in az_links_per_study:\n",
    "    page = read_in_page(link)\n",
    "    make_az_jsons_english(link, i, [\"Artificial Intelligence (Master's)\"])\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
