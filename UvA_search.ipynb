{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=10) #np.inf\n",
    "from scipy import spatial as cs\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a webpage\n",
    "def read_in_page(url):\n",
    "    #Query the website and return the html to the variable 'page'\n",
    "    page = urllib.urlopen(url)\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    return(soup)\n",
    "\n",
    "# Get all relevant links in a webpage\n",
    "def get_links(page):\n",
    "    links = page.find_all(\"a\", class_=\"action\")\n",
    "    links_new = []\n",
    "    for link in links:\n",
    "        sep = '?'\n",
    "        rest = link['href'].split(sep, 1)[0]\n",
    "        links_new.append(rest)\n",
    "    return(links_new)\n",
    "\n",
    "# Returns url of UvA search engine with keywords\n",
    "def create_search_query_url(keywords_list):\n",
    "    temp = keywords_list.copy()\n",
    "    main_url = \"http://student.uva.nl/search?q=\" + temp[0]\n",
    "    temp.remove(temp[0])\n",
    "    \n",
    "    for keyword in temp:\n",
    "        main_url = main_url + \"+\" + keyword\n",
    "    \n",
    "    return(main_url)\n",
    "\n",
    "# Returns a list of keywords when given a question URL.\n",
    "def get_keywords(question_url):\n",
    "    # grab keywords with beautiful soup\n",
    "    question_page = read_in_page(question_url)\n",
    "    keyword_tag = question_page.findAll(\"meta\", {\"name\": 'keywords'})\n",
    "    keywords = keyword_tag[0]['content']\n",
    "    return(keywords.split(','))\n",
    "\n",
    "# Create general vector for whole dictionary\n",
    "def general_vector(dictionary):\n",
    "    # first make a set to ensure no duplicates are added to the vector\n",
    "    general_vector = set()\n",
    "    # self explanatory\n",
    "    for faculty, studies in data.items():\n",
    "        for study, az_link in studies.items():\n",
    "            for article, keyword_lists in az_link.items():\n",
    "                for keyword_list in keyword_lists:\n",
    "                    keywords = keyword_list.split(',')\n",
    "                    for word in keywords:\n",
    "                        general_vector.add(word)\n",
    "    return list(general_vector)\n",
    "\n",
    "# Create vector for an article\n",
    "def vector(URL_keywords, general_vector):\n",
    "    # URL_keywords is a list of keywords for a certain URL we want a vector for\n",
    "    URL_vector = np.zeros(len(general_vector))\n",
    "    # loops through the (now zero) values of the URL vector\n",
    "    for i, val in enumerate(URL_vector):\n",
    "        # loops through the given keywords of this URL\n",
    "        for keyword in URL_keywords:\n",
    "            # if an article keyword matches a keyword in our general vector\n",
    "            if keyword == general_vector[i]:\n",
    "                # change the value of the URL vector to be 1 in the same place as the general vector\n",
    "                URL_vector[i] = 1\n",
    "    return URL_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('uva_json_file', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3471\n"
     ]
    }
   ],
   "source": [
    "generalvec = general_vector(data)\n",
    "print(len(generalvec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace dictionary keywords with vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 548 ms, total: 1min 46s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Replace the keywords of each article with a vector\n",
    "for faculty, studies in data.items():\n",
    "    for study, az_links in studies.items():\n",
    "        for article, keyword_lists in az_links.items():\n",
    "            for keyword_list in keyword_lists:\n",
    "                keywords = keyword_list.split(',')\n",
    "                vec = vector(keywords, generalvec)\n",
    "            # save vec in list form instead of np array \n",
    "            # because arrays don't work with json\n",
    "            az_links.update({article: vec}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input query keywords: ['toelatingseisen', 'kunstmatige', 'intelligentie']\n",
      "Query URL: http://student.uva.nl/search?q=toelatingseisen+kunstmatige+intelligentie \n",
      "\n",
      "Top 5 search results: ['http://www.uva.nl/programmas/bachelors/kunstmatige-intelligentie/toelating-en-inschrijven/toelatingseisen/toelatingseisen.html', 'http://www.uva.nl/shared-content/studentensites/fnwi/iw-gedeelde-content/nl/az/vakaanmelding/vakaanmelding.html', 'http://www.uva.nl/shared-content/studentensites/fnwi/iw-gedeelde-content/nl/az/bindend-studieadvies-bsa/bindend-studieadvies-bsa.html', 'http://www.student.uva.nl/ki', 'http://www.uva.nl/programmas/bachelors/kunstmatige-intelligentie/toelating-en-inschrijven/toelating-en-inschrijven.html'] \n",
      "\n",
      "Correct webpage URL: http://www.uva.nl/programmas/bachelors/kunstmatige-intelligentie/toelating-en-inschrijven/toelatingseisen/toelatingseisen.html\n",
      "Keywords of correct URL: ['faculteiten', 'natuurwetenschappen', ' wiskunde en informatica']\n"
     ]
    }
   ],
   "source": [
    "# Example test\n",
    "example_query = 'Wat zijn de toelatingseisen van kunstmatige intelligentie?'\n",
    "example_keyword_list = ['toelatingseisen', 'kunstmatige', 'intelligentie']\n",
    "example_url = create_search_query_url(example_keyword_list)\n",
    "\n",
    "print(\"Input query keywords:\", example_keyword_list)\n",
    "print(\"Query URL:\", example_url, \"\\n\")\n",
    "\n",
    "example_page = read_in_page(example_url)\n",
    "example_search_results = get_links(example_page)\n",
    "example_top_five = example_search_results[:5]\n",
    "print(\"Top 5 search results:\", example_top_five, \"\\n\")\n",
    "\n",
    "print(\"Correct webpage URL:\", example_search_results[0])\n",
    "result_keywords = get_keywords(example_search_results[0])\n",
    "print(\"Keywords of correct URL:\", result_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to test the whole process with an example query ('Wat zijn de toelatingseisen van kunstmatige intelligentie?'), but as shown above the correct webpage does not have the same keywords as the input query. Specifically, it does not have any keywords that would indicate the content of the article. \n",
    "\n",
    "However it is the first search result returned by the UvA search engine. Although, it needs to be said that the keywords needs to exactly match either the words in the url or the title of the article. Because the keyword 'ki' will not return the same results as 'kunstmatige', 'intelligentie', neither does 'ingangseisen' work.\n",
    "Moreover, we would not be able to calculate the cosine similarity or any kind of score based on matching keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test UvA search engine & cosine similarity scores\n",
    "In this test, we'll be using the UvA search engine. We'll use an example query and determine which words will be the keywords, these keywords will be put in the UvA search engine. A list of search results will be returned, and the cosine similarity scores will be calculated for the top 5 search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example test\n",
    "query = 'Wat zijn de toelatingseisen van kunstmatige intelligentie?' # example query\n",
    "query_keywords = ['toelatingseisen', 'kunstmatige', 'intelligentie'] # keywords from the query\n",
    "query_url = create_search_query_url(query_keywords) # resulting url of keywords put in search engine\n",
    "\n",
    "query_page = read_in_page(query_url) # read in query url\n",
    "search_results = get_links(query_page) # get the links of the search results\n",
    "top_five = search_results[:5] # get the links of the top 5 search results\n",
    "\n",
    "keywords = get_keywords(search_results[0]) # get the keywords of a search result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 1 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 2 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 3 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 4 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 5 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Define the query and top 5 article vectors\n",
    "query_vector = vector(query_keywords, generalvec)\n",
    "article1_vector = vector(search_results[0], generalvec)\n",
    "article2_vector = vector(search_results[1], generalvec)\n",
    "article3_vector = vector(search_results[2], generalvec)\n",
    "article4_vector = vector(search_results[3], generalvec)\n",
    "article5_vector = vector(search_results[4], generalvec)\n",
    "\n",
    "print(\"Query vector:\", query_vector)\n",
    "print(\"Article 1 vector:\", article1_vector)\n",
    "print(\"Article 2 vector:\", article2_vector)\n",
    "print(\"Article 3 vector:\", article3_vector)\n",
    "print(\"Article 4 vector:\", article4_vector)\n",
    "print(\"Article 5 vector:\", article5_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cosine similarities\n",
    "cosine_sim = 1 - cs.distance.cosine(article1_vector, query_vector)\n",
    "cosine_sim2 = 1 - cs.distance.cosine(article2_vector, query_vector)\n",
    "cosine_sim3 = 1 - cs.distance.cosine(article3_vector, query_vector)\n",
    "cosine_sim4 = 1 - cs.distance.cosine(article4_vector, query_vector)\n",
    "cosine_sim5 = 1 - cs.distance.cosine(article5_vector, query_vector)\n",
    "print(cosine_sim)\n",
    "print(cosine_sim2)\n",
    "print(cosine_sim3)\n",
    "print(cosine_sim4)\n",
    "print(cosine_sim5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above the correct webpage does not contain the same keywords as the input query, even though the correct webpage is incorporated in our json file. So this is not due to the limited reach of our data that the general vector depends on. The UvA search engine does return the correct results because the query keywords are also matched in the content of the article, even though they are not in the embedded keywords. This results in the cosine similarity being 0.0.\n",
    "\n",
    "It is also possible that the query keywords or article keywords do not appear in our data, since our data only consists of the A-Z pages. In that case, the vector will consist of only zero's such that a cosine similarity can not be calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Wat zijn de laptop eisen voor kunstmatige intelligentie? \n",
      "\n",
      "Input query keywords: ['laptop', 'eisen', 'kunstmatige', 'intelligentie'] \n",
      "\n",
      "Query URL: http://student.uva.nl/search?q=laptop+eisen+kunstmatige+intelligentie \n",
      "\n",
      "Search result #1: http://student.uva.nl/ki/content/az/laptop-minimumeisen/laptop-minimumeisen.html\n",
      "Keywords of article 1: ['minimumeisen', 'studenten', 'ict en faciliteiten', 'natuurwetenschappen', ' wiskunde en informatica', 'ict', 'computereisen', 'laptop', 'kunstmatige intelligentie'] \n",
      "\n",
      "Search result #2: http://www.uva.nl/shared-content/studentensites/fnwi/iw-gedeelde-content/nl/az/laptop-helpdesk/laptop-helpdesk.html\n",
      "Keywords of article 2: ['studenten'] \n",
      "\n",
      "Search result #3: http://www.uva.nl/shared-content/studentensites/fnwi/iw-gedeelde-content/nl/az/bindend-studieadvies-bsa/bindend-studieadvies-bsa.html\n",
      "Keywords of article 3: ['bindend studieadvies informatica', 'bsa kunstmatige intelligentie', 'studieprogramma', 'bindend studieadvies kunstmatige intelligentie', 'natuurwetenschappen', ' wiskunde en informatica', 'bindend studieadvies informatiekunde', 'onderwijs', 'bsa informatica', 'bsa inforrmatiekunde', 'advies en begeleiding'] \n",
      "\n",
      "Search result #4: http://www.uva.nl/shared-content/studentensites/fnwi/iis-gedeelde-content/nl/az/laptops/laptops.html\n",
      "Keywords of article 4: ['interdisciplinair', 'studieprogramma', 'ict en faciliteiten', 'ict'] \n",
      "\n",
      "Search result #5: http://www.uva.nl/shared-content/studentensites/fnwi/iw-gedeelde-content/nl/az/vakaanmelding/vakaanmelding.html\n",
      "Keywords of article 5: ['vakaanmelding', 'vakken', ' tentamens en cijfers', 'natuurwetenschappen', ' wiskunde en informatica']\n"
     ]
    }
   ],
   "source": [
    "# Example test\n",
    "query = 'Wat zijn de laptop eisen voor kunstmatige intelligentie?' # example query\n",
    "query_keywords = ['laptop', 'eisen', 'kunstmatige', 'intelligentie'] # keywords from the query\n",
    "query_url = create_search_query_url(query_keywords) # resulting url of keywords put in search engine\n",
    "\n",
    "query_page = read_in_page(query_url) # read in query url\n",
    "search_results = get_links(query_page) # get the links of the search results\n",
    "\n",
    "# get the keywords for the top 5 search results\n",
    "article1_keywords = get_keywords(search_results[0]) \n",
    "article2_keywords = get_keywords(search_results[1])\n",
    "article3_keywords = get_keywords(search_results[2])\n",
    "article4_keywords = get_keywords(search_results[3])\n",
    "article5_keywords = get_keywords(search_results[4])\n",
    "\n",
    "print(\"Query:\", query, \"\\n\")\n",
    "print(\"Input query keywords:\", query_keywords, \"\\n\")\n",
    "print(\"Query URL:\", query_url, \"\\n\")\n",
    "\n",
    "print(\"Search result #1:\", search_results[0])\n",
    "print(\"Keywords of article 1:\", article1_keywords, \"\\n\")\n",
    "print(\"Search result #2:\", search_results[1])\n",
    "print(\"Keywords of article 2:\", article2_keywords, \"\\n\")\n",
    "print(\"Search result #3:\", search_results[2])\n",
    "print(\"Keywords of article 3:\", article3_keywords, \"\\n\")\n",
    "print(\"Search result #4:\", search_results[3])\n",
    "print(\"Keywords of article 4:\", article4_keywords, \"\\n\")\n",
    "print(\"Search result #5:\", search_results[4])\n",
    "print(\"Keywords of article 5:\", article5_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 1 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 2 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 3 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 4 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 5 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Define the query and top 5 article vectors\n",
    "query_vector = vector(query_keywords, generalvec)\n",
    "article1_vector = vector(article1_keywords, generalvec)\n",
    "article2_vector = vector(article2_keywords, generalvec)\n",
    "article3_vector = vector(article3_keywords, generalvec)\n",
    "article4_vector = vector(article4_keywords, generalvec)\n",
    "article5_vector = vector(article5_keywords, generalvec)\n",
    "\n",
    "print(\"Query vector:\", query_vector)\n",
    "print(\"Article 1 vector:\", article1_vector)\n",
    "print(\"Article 2 vector:\", article2_vector)\n",
    "print(\"Article 3 vector:\", article3_vector)\n",
    "print(\"Article 4 vector:\", article4_vector)\n",
    "print(\"Article 5 vector:\", article5_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity article 1: 0.235702260396\n",
      "Cosine similarity article 2: 0.0\n",
      "Cosine similarity article 3: 0.0\n",
      "Cosine similarity article 4: 0.0\n",
      "Cosine similarity article 5: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cosine similarities\n",
    "cosine_sim1 = 1 - cs.distance.cosine(article1_vector, query_vector)\n",
    "cosine_sim2 = 1 - cs.distance.cosine(article2_vector, query_vector)\n",
    "cosine_sim3 = 1 - cs.distance.cosine(article3_vector, query_vector)\n",
    "cosine_sim4 = 1 - cs.distance.cosine(article4_vector, query_vector)\n",
    "cosine_sim5 = 1 - cs.distance.cosine(article5_vector, query_vector)\n",
    "\n",
    "print(\"Cosine similarity article 1:\", cosine_sim1)\n",
    "print(\"Cosine similarity article 2:\", cosine_sim2)\n",
    "print(\"Cosine similarity article 3:\", cosine_sim3)\n",
    "print(\"Cosine similarity article 4:\", cosine_sim4)\n",
    "print(\"Cosine similarity article 5:\", cosine_sim5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first article has a cosine similarity of 0.2357, whereas the rest of the articles has a cosine similarity of 0.0. So the first article has the highest probability of returning the correct answer. The difference between this test and the first test, is that some of the query keywords do appear in the keyword list of the search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
