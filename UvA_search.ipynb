{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=10) #np.inf\n",
    "from scipy import spatial as cs\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a webpage\n",
    "def read_in_page(url):\n",
    "    #Query the website and return the html to the variable 'page'\n",
    "    page = urllib.urlopen(url)\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    return(soup)\n",
    "\n",
    "# Get all relevant links in a webpage\n",
    "def get_links(page):\n",
    "    links = page.find_all(\"a\", class_=\"action\")\n",
    "    links_new = []\n",
    "    for link in links:\n",
    "        sep = '?'\n",
    "        rest = link['href'].split(sep, 1)[0]\n",
    "        links_new.append(rest)\n",
    "    return(links_new)\n",
    "\n",
    "# Returns url of UvA search engine with keywords\n",
    "def create_search_query_url(keywords_list):\n",
    "    main_url = \"http://student.uva.nl/search?q=\" + keywords_list[0]\n",
    "    keywords_list.remove(keywords_list[0])\n",
    "    \n",
    "    for keyword in keywords_list:\n",
    "        main_url = main_url + \"+\" + keyword\n",
    "    \n",
    "    return(main_url)\n",
    "\n",
    "# Returns a list of keywords when given a question URL.\n",
    "def get_keywords(question_url):\n",
    "    # grab keywords with beautiful soup\n",
    "    question_page = read_in_page(question_url)\n",
    "    keyword_tag = question_page.findAll(\"meta\", {\"name\": 'keywords'})\n",
    "    keywords = keyword_tag[0]['content']\n",
    "    return(keywords.split(','))\n",
    "\n",
    "# Create general vector for whole dictionary\n",
    "def general_vector(dictionary):\n",
    "    # first make a set to ensure no duplicates are added to the vector\n",
    "    general_vector = set()\n",
    "    # self explanatory\n",
    "    for faculty, studies in data.items():\n",
    "        for study, az_link in studies.items():\n",
    "            for article, keyword_lists in az_link.items():\n",
    "                for keyword_list in keyword_lists:\n",
    "                    keywords = keyword_list.split(',')\n",
    "                    for word in keywords:\n",
    "                        general_vector.add(word)\n",
    "    return list(general_vector)\n",
    "\n",
    "# Create vector for an article\n",
    "def vector(URL_keywords, general_vector):\n",
    "    # URL_keywords is a list of keywords for a certain URL we want a vector for\n",
    "    URL_vector = np.zeros(len(general_vector))\n",
    "    # loops through the (now zero) values of the URL vector\n",
    "    for i, val in enumerate(URL_vector):\n",
    "        # loops through the given keywords of this URL\n",
    "        for keyword in URL_keywords:\n",
    "            # if an article keyword matches a keyword in our general vector\n",
    "            if keyword == general_vector[i]:\n",
    "                # change the value of the URL vector to be 1 in the same place as the general vector\n",
    "                URL_vector[i] = 1\n",
    "    return URL_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input query keywords: ['kunstmatige', 'intelligentie']\n",
      "Query URL: http://student.uva.nl/search?q=toelatingseisen+kunstmatige+intelligentie \n",
      "\n",
      "Top 5 search results: ['http://www.uva.nl/programmas/bachelors/kunstmatige-intelligentie/toelating-en-inschrijven/toelatingseisen/toelatingseisen.html', 'http://www.uva.nl/shared-content/studentensites/fnwi/iw-gedeelde-content/nl/az/vakaanmelding/vakaanmelding.html', 'http://www.uva.nl/shared-content/studentensites/fnwi/iw-gedeelde-content/nl/az/bindend-studieadvies-bsa/bindend-studieadvies-bsa.html', 'http://www.student.uva.nl/ki', 'http://www.uva.nl/programmas/bachelors/kunstmatige-intelligentie/toelating-en-inschrijven/toelating-en-inschrijven.html'] \n",
      "\n",
      "Correct webpage URL: http://www.uva.nl/programmas/bachelors/kunstmatige-intelligentie/toelating-en-inschrijven/toelatingseisen/toelatingseisen.html\n",
      "Keywords of correct URL: ['faculteiten', 'natuurwetenschappen', ' wiskunde en informatica']\n"
     ]
    }
   ],
   "source": [
    "# Example test\n",
    "example_query = 'Wat zijn de toelatingseisen van kunstmatige intelligentie?'\n",
    "example_keywords = ['toelatingseisen', 'kunstmatige', 'intelligentie']\n",
    "example_url = create_search_query_url(example_keywords)\n",
    "print(\"Input query keywords:\", example_keywords)\n",
    "print(\"Query URL:\", example_url, \"\\n\")\n",
    "\n",
    "example_page = read_in_page(example_url)\n",
    "example_search_results = get_links(example_page)\n",
    "example_top_five = example_search_results[:5]\n",
    "print(\"Top 5 search results:\", example_top_five, \"\\n\")\n",
    "\n",
    "print(\"Correct webpage URL:\", example_search_results[0])\n",
    "result_keywords = get_keywords(example_search_results[0])\n",
    "print(\"Keywords of correct URL:\", result_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to test the whole process with an example query ('Wat zijn de toelatingseisen van kunstmatige intelligentie?'), but as shown above the correct webpage does not have the same keywords as the input query. Specifically, it does not have any keywords that would indicate the content of the article. \n",
    "\n",
    "However it is the first search result returned by the UvA search engine. Although, it needs to be said that the keywords needs to exactly match either the words in the url or the title of the article. Because the keyword 'ki' will not return the same results as 'kunstmatige', 'intelligentie', neither does 'ingangseisen' work.\n",
    "Moreover, we would not be able to calculate the cosine similarity or any kind of score based on matching keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import json file and replace dictionary keywords with vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('uva_json_file', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3471\n"
     ]
    }
   ],
   "source": [
    "generalvec = general_vector(data)\n",
    "print(len(generalvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 264 ms, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Replace the keywords of each article with a vector\n",
    "for faculty, studies in data.items():\n",
    "    for study, az_links in studies.items():\n",
    "        for article, keyword_lists in az_links.items():\n",
    "            for keyword_list in keyword_lists:\n",
    "                keywords = keyword_list.split(',')\n",
    "                vec = vector(keywords, generalvec)\n",
    "            # save vec in list form instead of np array \n",
    "            # because arrays don't work with json\n",
    "            az_links.update({article: vec}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test UvA search engine & cosine similarity scores\n",
    "In this test, we'll be using the UvA search engine. We'll use an example query and determine which words will be the keywords, these keywords will be put in the UvA search engine. A list of search results will be returned, and the cosien similarity scores will be calculated for the top 10 search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example test\n",
    "query = 'Wat zijn de toelatingseisen van kunstmatige intelligentie?' # example query\n",
    "query_keywords = ['toelatingseisen', 'kunstmatige', 'intelligentie'] # keywords from the query\n",
    "query_url = create_search_query_url(query_keywords) # resulting url of keywords put in search engine\n",
    "\n",
    "query_page = read_in_page(query_url) # read in query url\n",
    "search_results = get_links(query_page) # get the links of the search results\n",
    "top_five = search_results[:5] # get the links of the top 5 search results\n",
    "\n",
    "keywords = get_keywords(search_results[0]) # get the keywords of a search result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 1 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 2 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 3 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 4 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 5 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Define the query and top 5 article vectors\n",
    "query_vector = vector(query_keywords, generalvec)\n",
    "article1_vector = vector(search_results[0], generalvec)\n",
    "article2_vector = vector(search_results[1], generalvec)\n",
    "article3_vector = vector(search_results[2], generalvec)\n",
    "article4_vector = vector(search_results[3], generalvec)\n",
    "article5_vector = vector(search_results[4], generalvec)\n",
    "\n",
    "print(\"Query vector:\", query_vector)\n",
    "print(\"Article 1 vector:\", article1_vector)\n",
    "print(\"Article 2 vector:\", article2_vector)\n",
    "print(\"Article 3 vector:\", article3_vector)\n",
    "print(\"Article 4 vector:\", article4_vector)\n",
    "print(\"Article 5 vector:\", article5_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Iris/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cosine similarities\n",
    "cosine_sim = 1 - cs.distance.cosine(article1_vector, query_vector)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above the correct webpage does not contain the same keywords as the input query, even though the correct webpage is incorporated in our json file, so those keywords do appear in our general vector. However, the query keywords are matched in the content of the article, just not the embedded keywords. This results in the query vector consisting of only zero's, so it's impossible to calculate the cosine similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example test\n",
    "query = 'Wat zijn de laptop eisen voor kunstmatige intelligentie?' # example query\n",
    "query_keywords = ['eisen', 'kunstmatige', 'intelligentie', 'laptop'] # keywords from the query\n",
    "query_url = create_search_query_url(query_keywords) # resulting url of keywords put in search engine\n",
    "\n",
    "query_page = read_in_page(query_url) # read in query url\n",
    "search_results = get_links(query_page) # get the links of the search results\n",
    "\n",
    "# get the keywords for the top 5 search results\n",
    "article1_keywords = get_keywords(search_results[0]) \n",
    "article2_keywords = get_keywords(search_results[1])\n",
    "article3_keywords = get_keywords(search_results[2])\n",
    "article4_keywords = get_keywords(search_results[3])\n",
    "article5_keywords = get_keywords(search_results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 1 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 2 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 3 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 4 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Article 5 vector: [ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Define the query and top 5 article vectors\n",
    "query_vector = vector(query_keywords, generalvec)\n",
    "article1_vector = vector(article1_keywords, generalvec)\n",
    "article2_vector = vector(article2_keywords, generalvec)\n",
    "article3_vector = vector(article3_keywords, generalvec)\n",
    "article4_vector = vector(article4_keywords, generalvec)\n",
    "article5_vector = vector(article5_keywords, generalvec)\n",
    "\n",
    "print(\"Query vector:\", query_vector)\n",
    "print(\"Article 1 vector:\", article1_vector)\n",
    "print(\"Article 2 vector:\", article2_vector)\n",
    "print(\"Article 3 vector:\", article3_vector)\n",
    "print(\"Article 4 vector:\", article4_vector)\n",
    "print(\"Article 5 vector:\", article5_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333333333333\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cosine similarities\n",
    "cosine_sim1 = 1 - cs.distance.cosine(article1_vector, query_vector)\n",
    "cosine_sim2 = 1 - cs.distance.cosine(article2_vector, query_vector)\n",
    "cosine_sim3 = 1 - cs.distance.cosine(article3_vector, query_vector)\n",
    "cosine_sim4 = 1 - cs.distance.cosine(article4_vector, query_vector)\n",
    "cosine_sim5 = 1 - cs.distance.cosine(article5_vector, query_vector)\n",
    "\n",
    "print(cosine_sim1)\n",
    "print(cosine_sim2)\n",
    "print(cosine_sim3)\n",
    "print(cosine_sim4)\n",
    "print(cosine_sim5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first article has a cosine similarity of 0.333, whereas the rest of the articles has a cosine similarity of 0.0. So the first article has the highest probability of returning the answer. The difference between this test and the first test, is that some of the query keywords do appear in the keyword list of the search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query keywords: ['kunstmatige', 'intelligentie', 'laptop'] \n",
      "\n",
      "URL of first article: http://student.uva.nl/ki/content/az/laptop-minimumeisen/laptop-minimumeisen.html\n",
      "Keywords of the first article: ['minimumeisen', 'studenten', 'ict en faciliteiten', 'natuurwetenschappen', ' wiskunde en informatica', 'ict', 'computereisen', 'laptop', 'kunstmatige intelligentie']\n"
     ]
    }
   ],
   "source": [
    "print(\"Query keywords:\", query_keywords, \"\\n\")\n",
    "print(\"URL of first article:\", search_results[0])\n",
    "print(\"Keywords of the first article:\", article1_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
